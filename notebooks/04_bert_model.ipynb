{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - BERT Fine-Tuning for Assignment\n",
    "\n",
    "This notebook fine-tunes DistilBERT for 3-class support ticket classification.\n",
    "\n",
    "**For Assignment Submission:**\n",
    "- Loads pre-trained DistilBERT from HuggingFace\n",
    "- Fine-tunes on training data\n",
    "- Evaluates on validation and test sets\n",
    "- Saves best model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_scheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from src.data_utils import load_text_classification_data\n",
    "from src.model.bert_model import BertClassifier, get_tokenizer\n",
    "from src.train_nn import train_epoch_with_scheduler, eval_epoch_bert\n",
    "from src.evaluate import evaluate_classification\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data splits\n",
    "train_texts, train_labels, label2id, id2label = load_text_classification_data('train')\n",
    "val_texts, val_labels, _, _ = load_text_classification_data('val')\n",
    "test_texts, test_labels, _, _ = load_text_classification_data('test')\n",
    "\n",
    "# Basic preprocessing (strip whitespace)\n",
    "train_texts = [text.strip() for text in train_texts]\n",
    "val_texts = [text.strip() for text in val_texts]\n",
    "test_texts = [text.strip() for text in test_texts]\n",
    "\n",
    "print(f\"Training samples: {len(train_texts)}\")\n",
    "print(f\"Validation samples: {len(val_texts)}\")\n",
    "print(f\"Test samples: {len(test_texts)}\")\n",
    "print(f\"Label mapping: {label2id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "model_name = 'distilbert-base-uncased'  # Will download from HuggingFace\n",
    "max_length = 128  # Max sequence length for tokenization\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "print(f\"Tokenizer loaded: {model_name}\")\n",
    "print(f\"Max length: {max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    \"\"\"Dataset for BERT text classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = BertDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = BertDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "test_dataset = BertDataset(test_texts, test_labels, tokenizer, max_length)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT classifier\n",
    "model = BertClassifier(\n",
    "    model_name=model_name,\n",
    "    num_classes=3,\n",
    "    dropout=0.3,\n",
    "    freeze_bert=False  # Full fine-tuning\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "# Class weights for imbalanced data\n",
    "class_counts = np.bincount(train_labels)\n",
    "class_weights = (len(train_labels) / (len(class_counts) * class_counts)).astype(np.float32)\n",
    "class_weights_tensor = torch.tensor(class_weights, device=device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "num_epochs = 3\n",
    "num_training_steps = len(train_loader) * num_epochs\n",
    "num_warmup_steps = int(0.1 * num_training_steps)\n",
    "\n",
    "scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "print(f\"Training for {num_epochs} epochs\")\n",
    "print(f\"Total steps: {num_training_steps}\")\n",
    "print(f\"Warmup steps: {num_warmup_steps}\")\n",
    "print(f\"Initial learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "print(f\"Class weights: {class_weights.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_val_acc = 0\n",
    "best_model_state = None\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch_with_scheduler(\n",
    "        train_loader, model, criterion, optimizer, scheduler, device\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, _, _ = eval_epoch_bert(val_loader, model, criterion, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  ✓ New best validation accuracy: {best_val_acc:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"✓ Loaded best model with validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_acc, val_pred, val_true = eval_epoch_bert(val_loader, model, criterion, device)\n",
    "\n",
    "val_results = evaluate_classification(val_true, val_pred)\n",
    "print(\"Validation Results:\")\n",
    "print(f\"Accuracy: {val_results['accuracy']:.4f}\")\n",
    "print(f\"F1 Macro: {val_results['f1_macro']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(val_results['report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_pred, test_true = eval_epoch_bert(test_loader, model, criterion, device)\n",
    "\n",
    "test_results = evaluate_classification(test_true, test_pred)\n",
    "print(\"Test Results:\")\n",
    "print(f\"Accuracy: {test_results['accuracy']:.4f}\")\n",
    "print(f\"F1 Macro: {test_results['f1_macro']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(test_results['report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for validation set\n",
    "label_names = [id2label[i] for i in sorted(id2label.keys())]\n",
    "cm = confusion_matrix(val_true, val_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=label_names\n",
    ")\n",
    "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix (Validation Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Validation Accuracy: {val_results['accuracy']:.4f}\")\n",
    "print(f\"Validation F1 Macro: {val_results['f1_macro']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "import os\n",
    "\n",
    "os.makedirs('../src/model', exist_ok=True)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_name': model_name,\n",
    "    'label2id': label2id,\n",
    "    'id2label': id2label,\n",
    "    'num_classes': 3\n",
    "}, '../src/model/bert_finetuned.pt')\n",
    "\n",
    "print(\"✓ Model saved to ../src/model/bert_finetuned.pt\")\n",
    "print(f\"  - Validation Accuracy: {val_results['accuracy']:.4f}\")\n",
    "print(f\"  - Test Accuracy: {test_results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Model:** DistilBERT (distilbert-base-uncased)\n",
    "\n",
    "**Configuration:**\n",
    "- Full fine-tuning (all parameters trainable)\n",
    "- Learning rate: 2e-5 with linear warmup\n",
    "- Batch size: 32\n",
    "- Epochs: 3\n",
    "- Max sequence length: 128\n",
    "\n",
    "**Results:**\n",
    "- Validation Accuracy: ~75%\n",
    "- Test Accuracy: ~75%\n",
    "- F1 Macro Score: ~75%\n",
    "\n",
    "**For Assignment:**\n",
    "- This notebook demonstrates complete BERT fine-tuning workflow\n",
    "- Model saved and ready for evaluation in assignment report\n",
    "- See `05_error_analysis.ipynb` for model comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
